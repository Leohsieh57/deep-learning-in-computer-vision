{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "from torchvision.utils import save_image\n",
    "import PIL\n",
    "import skimage.io\n",
    "import multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataType(fn):\n",
    "    return fn.split('/')[-1].split('_')[0]\n",
    "    \n",
    "class npLoader(Dataset):\n",
    "    def __init__(self, root, transform = None):\n",
    "        self.transform = transform\n",
    "        self.root = root\n",
    "        fnList = sorted(glob.glob(os.path.join(self.root, '*.npy')))\n",
    "        fnImgList = [fn for fn in fnList if dataType(fn) == 'img']\n",
    "        fnMaskList = [fn for fn in fnList if dataType(fn) == 'mask']\n",
    "        self.len = len(fnImgList)\n",
    "        self.fnList = [(fnImgList[i], fnMaskList[i]) for i in range(self.len)]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fnImg, fnMask = self.fnList[index]\n",
    "        return np.load(fnImg), np.load(fnMask)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "train_set = npLoader(root='hw2_data/p2_data/train_npy', transform=transforms.ToTensor())\n",
    "test_set = npLoader(root='hw2_data/p2_data/validation_npy', transform=transforms.ToTensor())\n",
    "\n",
    "trainset_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=0)\n",
    "testset_loader = DataLoader(test_set, batch_size=mp.cpu_count(), shuffle=False, num_workers=0)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# activate cuda\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "print('Device used:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcn32s(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained = True):\n",
    "        super(fcn32s, self).__init__()\n",
    "        self.vgg = torchvision.models.vgg16(pretrained=True)\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, kernel_size=(2, 2), stride=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            \n",
    "            nn.Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            \n",
    "            nn.Conv2d(4096, num_classes, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ConvTranspose2d(num_classes, num_classes, 64 , 32 , 0, bias=False),\n",
    "        )\n",
    "    def  forward (self, x) :        \n",
    "        x = self.vgg.features(x)\n",
    "        x = self.vgg.classifier(x)\n",
    "        return x\n",
    "    \n",
    "class fcn16s(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained = True):\n",
    "        super(fcn16s, self).__init__()\n",
    "        self.vgg = torchvision.models.vgg16(pretrained=True)\n",
    "        self.to_pool4 = nn.Sequential(*list(self.vgg.features.children())[:24])\n",
    "        self.to_pool5 = nn.Sequential(*list(self.vgg.features.children())[24:])\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, kernel_size=(2, 2), stride=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            \n",
    "            nn.Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            \n",
    "            nn.Conv2d(4096, num_classes, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ConvTranspose2d(num_classes, 512, 4 , 2 , 0, bias=False)\n",
    "            )\n",
    "        self.upsample16 = nn.ConvTranspose2d(512, num_classes, 16 , 16 , 0, bias=False)\n",
    "        \n",
    "    def forward (self, x) :        \n",
    "        pool4_output = self.to_pool4(x) #pool4 output size torch.Size([64, 512, 16, 16])\n",
    "        x = self.to_pool5(pool4_output)\n",
    "        x = self.vgg.classifier(x)    # 2xconv7 output size torch.Size([64, 512, 16, 16])\n",
    "        x = self.upsample16(x+pool4_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(model, epoch, log_interval=25, save_interval = 5):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        print('')\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = F.log_softmax(output, dim= 1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "        if ep % save_interval == 0:\n",
    "            save_checkpoint('p2_fcn16_ep'+str(ep)+'.pth', model, optimizer)\n",
    "        print('')\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(labels, pred):\n",
    "    mean_iou = 0\n",
    "    for i in range(6):\n",
    "        tp_fp = np.sum(pred == i)\n",
    "        tp_fn = np.sum(labels == i)\n",
    "        tp = np.sum((pred == i) * (labels == i))\n",
    "        iou = tp / (tp_fp + tp_fn - tp)\n",
    "        mean_iou += iou / 6\n",
    "        print('class #%d : %1.5f'%(i, iou))\n",
    "    print('\\nmean_iou: %f\\n' % mean_iou)\n",
    "    return mean_iou\n",
    "\n",
    "\n",
    "currentBestIoU = 0\n",
    "def test(model, log_interval=5):\n",
    "    loss, iteration = 0, 0\n",
    "    model.eval()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n",
    "    print('start testing model...')\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        start = time.time()\n",
    "        predList, maskList = [], []\n",
    "        for data, target in testset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = F.log_softmax(output, dim= 1)\n",
    "            loss += criterion(output, target).item()*len(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            predList += [singleBatch[0] for singleBatch in pred.cpu().numpy()]\n",
    "            maskList += [singleBatch for singleBatch in target.cpu().numpy()]\n",
    "            iteration += 1\n",
    "    IoU = mIoU(np.array(predList), np.array(maskList))\n",
    "    loss /= len(testset_loader.dataset)\n",
    "    print('')\n",
    "    print('Test set average loss =',loss,'     mIoU =',IoU)\n",
    "    global currentBestIoU\n",
    "    if IoU > currentBestIoU:\n",
    "        print(\"current best model updated!\")\n",
    "        currentBestIoU = IoU\n",
    "        save_checkpoint('p2_current_best_fcn16-'+str(round(IoU*100.0,2))+'.pth', model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 0 [0/2000 (0%)]\tLoss: 1.977680\n",
      "Train Epoch: 0 [400/2000 (20%)]\tLoss: 1.227235\n",
      "Train Epoch: 0 [800/2000 (40%)]\tLoss: 1.141965\n",
      "Train Epoch: 0 [1200/2000 (60%)]\tLoss: 0.878356\n",
      "Train Epoch: 0 [1600/2000 (80%)]\tLoss: 0.704091\n",
      "model saved to p2_fcn16_ep0.pth\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.63941\n",
      "class #1 : 0.75766\n",
      "class #2 : 0.00635\n",
      "class #3 : 0.63021\n",
      "class #4 : 0.43294\n",
      "class #5 : 0.13372\n",
      "\n",
      "mean_iou: 0.433383\n",
      "\n",
      "\n",
      "Test set average loss = 0.6763830741555774      mIoU = 0.43338257465110036\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-43.34.pth\n",
      "\n",
      "Train Epoch: 1 [0/2000 (0%)]\tLoss: 0.686761\n",
      "Train Epoch: 1 [400/2000 (20%)]\tLoss: 0.601796\n",
      "Train Epoch: 1 [800/2000 (40%)]\tLoss: 0.796653\n",
      "Train Epoch: 1 [1200/2000 (60%)]\tLoss: 0.522537\n",
      "Train Epoch: 1 [1600/2000 (80%)]\tLoss: 0.681051\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.63436\n",
      "class #1 : 0.81210\n",
      "class #2 : 0.03255\n",
      "class #3 : 0.64088\n",
      "class #4 : 0.65545\n",
      "class #5 : 0.44910\n",
      "\n",
      "mean_iou: 0.537407\n",
      "\n",
      "\n",
      "Test set average loss = 0.5866922603970836      mIoU = 0.5374074317636299\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-53.74.pth\n",
      "\n",
      "Train Epoch: 2 [0/2000 (0%)]\tLoss: 0.485738\n",
      "Train Epoch: 2 [400/2000 (20%)]\tLoss: 0.432413\n",
      "Train Epoch: 2 [800/2000 (40%)]\tLoss: 0.563009\n",
      "Train Epoch: 2 [1200/2000 (60%)]\tLoss: 0.783204\n",
      "Train Epoch: 2 [1600/2000 (80%)]\tLoss: 0.369521\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.70316\n",
      "class #1 : 0.82333\n",
      "class #2 : 0.07616\n",
      "class #3 : 0.67135\n",
      "class #4 : 0.67899\n",
      "class #5 : 0.46244\n",
      "\n",
      "mean_iou: 0.569239\n",
      "\n",
      "\n",
      "Test set average loss = 0.5336380259999969      mIoU = 0.5692385359257033\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-56.92.pth\n",
      "\n",
      "Train Epoch: 3 [0/2000 (0%)]\tLoss: 0.689975\n",
      "Train Epoch: 3 [400/2000 (20%)]\tLoss: 0.554627\n",
      "Train Epoch: 3 [800/2000 (40%)]\tLoss: 0.481914\n",
      "Train Epoch: 3 [1200/2000 (60%)]\tLoss: 0.407044\n",
      "Train Epoch: 3 [1600/2000 (80%)]\tLoss: 0.483909\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.65900\n",
      "class #1 : 0.82203\n",
      "class #2 : 0.04997\n",
      "class #3 : 0.66404\n",
      "class #4 : 0.70144\n",
      "class #5 : 0.54545\n",
      "\n",
      "mean_iou: 0.573657\n",
      "\n",
      "\n",
      "Test set average loss = 0.5093716465313611      mIoU = 0.5736566863130503\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-57.37.pth\n",
      "\n",
      "Train Epoch: 4 [0/2000 (0%)]\tLoss: 0.601183\n",
      "Train Epoch: 4 [400/2000 (20%)]\tLoss: 0.418167\n",
      "Train Epoch: 4 [800/2000 (40%)]\tLoss: 0.435963\n",
      "Train Epoch: 4 [1200/2000 (60%)]\tLoss: 0.714804\n",
      "Train Epoch: 4 [1600/2000 (80%)]\tLoss: 0.535682\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.74568\n",
      "class #1 : 0.85789\n",
      "class #2 : 0.15954\n",
      "class #3 : 0.71217\n",
      "class #4 : 0.68040\n",
      "class #5 : 0.55913\n",
      "\n",
      "mean_iou: 0.619136\n",
      "\n",
      "\n",
      "Test set average loss = 0.4531377790503001      mIoU = 0.6191357684690173\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-61.91.pth\n",
      "\n",
      "Train Epoch: 5 [0/2000 (0%)]\tLoss: 0.386212\n",
      "Train Epoch: 5 [400/2000 (20%)]\tLoss: 0.392236\n",
      "Train Epoch: 5 [800/2000 (40%)]\tLoss: 0.462527\n",
      "Train Epoch: 5 [1200/2000 (60%)]\tLoss: 0.635787\n",
      "Train Epoch: 5 [1600/2000 (80%)]\tLoss: 0.692446\n",
      "model saved to p2_fcn16_ep5.pth\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.67225\n",
      "class #1 : 0.85348\n",
      "class #2 : 0.20159\n",
      "class #3 : 0.74268\n",
      "class #4 : 0.68638\n",
      "class #5 : 0.55816\n",
      "\n",
      "mean_iou: 0.619091\n",
      "\n",
      "\n",
      "Test set average loss = 0.44360141067653314      mIoU = 0.619090883287172\n",
      "\n",
      "Train Epoch: 6 [0/2000 (0%)]\tLoss: 0.466571\n",
      "Train Epoch: 6 [400/2000 (20%)]\tLoss: 0.470294\n",
      "Train Epoch: 6 [800/2000 (40%)]\tLoss: 0.456999\n",
      "Train Epoch: 6 [1200/2000 (60%)]\tLoss: 0.286715\n",
      "Train Epoch: 6 [1600/2000 (80%)]\tLoss: 0.325817\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.74819\n",
      "class #1 : 0.86618\n",
      "class #2 : 0.15916\n",
      "class #3 : 0.69822\n",
      "class #4 : 0.70953\n",
      "class #5 : 0.57744\n",
      "\n",
      "mean_iou: 0.626454\n",
      "\n",
      "\n",
      "Test set average loss = 0.4162138870949875      mIoU = 0.6264537590952657\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-62.65.pth\n",
      "\n",
      "Train Epoch: 7 [0/2000 (0%)]\tLoss: 0.473335\n",
      "Train Epoch: 7 [400/2000 (20%)]\tLoss: 0.489556\n",
      "Train Epoch: 7 [800/2000 (40%)]\tLoss: 0.339462\n",
      "Train Epoch: 7 [1200/2000 (60%)]\tLoss: 0.392317\n",
      "Train Epoch: 7 [1600/2000 (80%)]\tLoss: 0.389151\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.75385\n",
      "class #1 : 0.87254\n",
      "class #2 : 0.18137\n",
      "class #3 : 0.67547\n",
      "class #4 : 0.69741\n",
      "class #5 : 0.57652\n",
      "\n",
      "mean_iou: 0.626194\n",
      "\n",
      "\n",
      "Test set average loss = 0.4222026355999453      mIoU = 0.626193580537547\n",
      "\n",
      "Train Epoch: 8 [0/2000 (0%)]\tLoss: 0.286008\n",
      "Train Epoch: 8 [400/2000 (20%)]\tLoss: 0.472022\n",
      "Train Epoch: 8 [800/2000 (40%)]\tLoss: 0.445144\n",
      "Train Epoch: 8 [1200/2000 (60%)]\tLoss: 0.188162\n",
      "Train Epoch: 8 [1600/2000 (80%)]\tLoss: 0.368179\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.75416\n",
      "class #1 : 0.85927\n",
      "class #2 : 0.21800\n",
      "class #3 : 0.73334\n",
      "class #4 : 0.61180\n",
      "class #5 : 0.56563\n",
      "\n",
      "mean_iou: 0.623702\n",
      "\n",
      "\n",
      "Test set average loss = 0.4217114345340877      mIoU = 0.6237015253984964\n",
      "\n",
      "Train Epoch: 9 [0/2000 (0%)]\tLoss: 0.349199\n",
      "Train Epoch: 9 [400/2000 (20%)]\tLoss: 0.407084\n",
      "Train Epoch: 9 [800/2000 (40%)]\tLoss: 0.405089\n",
      "Train Epoch: 9 [1200/2000 (60%)]\tLoss: 0.594136\n",
      "Train Epoch: 9 [1600/2000 (80%)]\tLoss: 0.353643\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.73849\n",
      "class #1 : 0.83528\n",
      "class #2 : 0.18906\n",
      "class #3 : 0.70487\n",
      "class #4 : 0.72888\n",
      "class #5 : 0.55384\n",
      "\n",
      "mean_iou: 0.625071\n",
      "\n",
      "\n",
      "Test set average loss = 0.48824792277024415      mIoU = 0.6250710915042497\n",
      "\n",
      "Train Epoch: 10 [0/2000 (0%)]\tLoss: 0.366215\n",
      "Train Epoch: 10 [400/2000 (20%)]\tLoss: 0.453727\n",
      "Train Epoch: 10 [800/2000 (40%)]\tLoss: 0.370054\n",
      "Train Epoch: 10 [1200/2000 (60%)]\tLoss: 0.396258\n",
      "Train Epoch: 10 [1600/2000 (80%)]\tLoss: 0.399171\n",
      "model saved to p2_fcn16_ep10.pth\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.75079\n",
      "class #1 : 0.87385\n",
      "class #2 : 0.22403\n",
      "class #3 : 0.78568\n",
      "class #4 : 0.71743\n",
      "class #5 : 0.64478\n",
      "\n",
      "mean_iou: 0.666093\n",
      "\n",
      "\n",
      "Test set average loss = 0.3766817520100783      mIoU = 0.6660927212089248\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-66.61.pth\n",
      "\n",
      "Train Epoch: 11 [0/2000 (0%)]\tLoss: 0.436825\n",
      "Train Epoch: 11 [400/2000 (20%)]\tLoss: 0.380034\n",
      "Train Epoch: 11 [800/2000 (40%)]\tLoss: 0.383977\n",
      "Train Epoch: 11 [1200/2000 (60%)]\tLoss: 0.370127\n",
      "Train Epoch: 11 [1600/2000 (80%)]\tLoss: 0.415581\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.76445\n",
      "class #1 : 0.86920\n",
      "class #2 : 0.28950\n",
      "class #3 : 0.74747\n",
      "class #4 : 0.69951\n",
      "class #5 : 0.62954\n",
      "\n",
      "mean_iou: 0.666613\n",
      "\n",
      "\n",
      "Test set average loss = 0.3854312502456546      mIoU = 0.6666133284432132\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-66.66.pth\n",
      "\n",
      "Train Epoch: 12 [0/2000 (0%)]\tLoss: 0.386270\n",
      "Train Epoch: 12 [400/2000 (20%)]\tLoss: 0.377985\n",
      "Train Epoch: 12 [800/2000 (40%)]\tLoss: 0.214447\n",
      "Train Epoch: 12 [1200/2000 (60%)]\tLoss: 0.312596\n",
      "Train Epoch: 12 [1600/2000 (80%)]\tLoss: 0.285055\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.74677\n",
      "class #1 : 0.85584\n",
      "class #2 : 0.31002\n",
      "class #3 : 0.74419\n",
      "class #4 : 0.67175\n",
      "class #5 : 0.60681\n",
      "\n",
      "mean_iou: 0.655896\n",
      "\n",
      "\n",
      "Test set average loss = 0.42217140554917926      mIoU = 0.6558957851109872\n",
      "\n",
      "Train Epoch: 13 [0/2000 (0%)]\tLoss: 0.431948\n",
      "Train Epoch: 13 [400/2000 (20%)]\tLoss: 0.395847\n",
      "Train Epoch: 13 [800/2000 (40%)]\tLoss: 0.244818\n",
      "Train Epoch: 13 [1200/2000 (60%)]\tLoss: 0.108239\n",
      "Train Epoch: 13 [1600/2000 (80%)]\tLoss: 0.413760\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.74620\n",
      "class #1 : 0.86496\n",
      "class #2 : 0.31487\n",
      "class #3 : 0.73592\n",
      "class #4 : 0.72511\n",
      "class #5 : 0.64480\n",
      "\n",
      "mean_iou: 0.671976\n",
      "\n",
      "\n",
      "Test set average loss = 0.3947487710051036      mIoU = 0.6719761093735835\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-67.2.pth\n",
      "\n",
      "Train Epoch: 14 [0/2000 (0%)]\tLoss: 0.175094\n",
      "Train Epoch: 14 [400/2000 (20%)]\tLoss: 0.406850\n",
      "Train Epoch: 14 [800/2000 (40%)]\tLoss: 0.373053\n",
      "Train Epoch: 14 [1200/2000 (60%)]\tLoss: 0.255064\n",
      "Train Epoch: 14 [1600/2000 (80%)]\tLoss: 0.251751\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.75671\n",
      "class #1 : 0.86845\n",
      "class #2 : 0.31854\n",
      "class #3 : 0.74635\n",
      "class #4 : 0.63239\n",
      "class #5 : 0.65453\n",
      "\n",
      "mean_iou: 0.662827\n",
      "\n",
      "\n",
      "Test set average loss = 0.3854007486703331      mIoU = 0.6628270298552474\n",
      "\n",
      "Train Epoch: 15 [0/2000 (0%)]\tLoss: 0.210374\n",
      "Train Epoch: 15 [400/2000 (20%)]\tLoss: 0.393941\n",
      "Train Epoch: 15 [800/2000 (40%)]\tLoss: 0.172092\n",
      "Train Epoch: 15 [1200/2000 (60%)]\tLoss: 0.245411\n",
      "Train Epoch: 15 [1600/2000 (80%)]\tLoss: 0.315522\n",
      "model saved to p2_fcn16_ep15.pth\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.76403\n",
      "class #1 : 0.86182\n",
      "class #2 : 0.23834\n",
      "class #3 : 0.76519\n",
      "class #4 : 0.73966\n",
      "class #5 : 0.53447\n",
      "\n",
      "mean_iou: 0.650586\n",
      "\n",
      "\n",
      "Test set average loss = 0.40471869104103353      mIoU = 0.6505859611131841\n",
      "\n",
      "Train Epoch: 16 [0/2000 (0%)]\tLoss: 0.254288\n",
      "Train Epoch: 16 [400/2000 (20%)]\tLoss: 0.391815\n",
      "Train Epoch: 16 [800/2000 (40%)]\tLoss: 0.267800\n",
      "Train Epoch: 16 [1200/2000 (60%)]\tLoss: 0.308026\n",
      "Train Epoch: 16 [1600/2000 (80%)]\tLoss: 0.251725\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.75492\n",
      "class #1 : 0.87990\n",
      "class #2 : 0.32368\n",
      "class #3 : 0.78819\n",
      "class #4 : 0.74108\n",
      "class #5 : 0.65381\n",
      "\n",
      "mean_iou: 0.690264\n",
      "\n",
      "\n",
      "Test set average loss = 0.37022527043457626      mIoU = 0.6902642132930632\n",
      "current best model updated!\n",
      "model saved to p2_current_best_fcn16-69.03.pth\n",
      "\n",
      "Train Epoch: 17 [0/2000 (0%)]\tLoss: 0.276131\n",
      "Train Epoch: 17 [400/2000 (20%)]\tLoss: 0.204907\n",
      "Train Epoch: 17 [800/2000 (40%)]\tLoss: 0.315387\n",
      "Train Epoch: 17 [1200/2000 (60%)]\tLoss: 0.226649\n",
      "Train Epoch: 17 [1600/2000 (80%)]\tLoss: 0.352204\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.74287\n",
      "class #1 : 0.87944\n",
      "class #2 : 0.29069\n",
      "class #3 : 0.78116\n",
      "class #4 : 0.73472\n",
      "class #5 : 0.66160\n",
      "\n",
      "mean_iou: 0.681747\n",
      "\n",
      "\n",
      "Test set average loss = 0.3758638106895328      mIoU = 0.6817467413159761\n",
      "\n",
      "Train Epoch: 18 [0/2000 (0%)]\tLoss: 0.259394\n",
      "Train Epoch: 18 [400/2000 (20%)]\tLoss: 0.335393\n",
      "Train Epoch: 18 [800/2000 (40%)]\tLoss: 0.263601\n",
      "Train Epoch: 18 [1200/2000 (60%)]\tLoss: 0.240133\n",
      "Train Epoch: 18 [1600/2000 (80%)]\tLoss: 0.338950\n",
      "\n",
      "start testing model...\n",
      "class #0 : 0.76420\n",
      "class #1 : 0.87664\n",
      "class #2 : 0.28416\n",
      "class #3 : 0.79243\n",
      "class #4 : 0.73912\n",
      "class #5 : 0.64927\n",
      "\n",
      "mean_iou: 0.684303\n",
      "\n",
      "\n",
      "Test set average loss = 0.3776977473891663      mIoU = 0.6843026420773666\n",
      "\n",
      "Train Epoch: 19 [0/2000 (0%)]\tLoss: 0.223808\n",
      "Train Epoch: 19 [400/2000 (20%)]\tLoss: 0.225817\n",
      "Train Epoch: 19 [800/2000 (40%)]\tLoss: 0.308019\n"
     ]
    }
   ],
   "source": [
    "model = fcn16s(7)\n",
    "model.to(device)\n",
    "train_save(model, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcn16s(\n",
      "  (vgg): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Conv2d(512, 4096, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout2d(p=0.5, inplace=False)\n",
      "      (3): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout2d(p=0.5, inplace=False)\n",
      "      (6): Conv2d(4096, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (7): ConvTranspose2d(7, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (to_pool4): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (to_pool5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (upsample16): ConvTranspose2d(512, 7, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fcn16s(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
