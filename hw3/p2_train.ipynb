{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "from torchvision.utils import save_image\n",
    "import PIL\n",
    "from models import Generator, Discriminator\n",
    "import training_helper as th\n",
    "from torch.autograd import Variable\n",
    "import training_helper as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda:1\n"
     ]
    }
   ],
   "source": [
    "#preperations\n",
    "trainset = th.imgData(root='hw3_data/p1_npy')\n",
    "trainset_loader = DataLoader(trainset, batch_size=2048, shuffle=True, num_workers=0)\n",
    "\n",
    "device = th.getCudaDevice(cudaNum = 1, torchSeed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "lr changed\n",
      "training D Loss: 0.00019683934738859535\n",
      "training G Loss: 0.003211895942687988\n",
      "D_real_acc: 0.924625\n",
      "D_fake_acc: 0.933925\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 1\n",
      "training D Loss: 0.0003214646354143042\n",
      "training G Loss: 0.005717286694049835\n",
      "D_real_acc: 0.908325\n",
      "D_fake_acc: 0.84935\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 2\n",
      "training D Loss: 0.00032633765414357183\n",
      "training G Loss: 0.003469477987289429\n",
      "D_real_acc: 0.9089\n",
      "D_fake_acc: 0.85985\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 3\n",
      "training D Loss: 0.00037180236987769603\n",
      "training G Loss: 0.002066770645976067\n",
      "D_real_acc: 0.8101\n",
      "D_fake_acc: 0.806125\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 4\n",
      "training D Loss: 0.0004962743058800698\n",
      "training G Loss: 0.0016637030623853208\n",
      "D_real_acc: 0.8003\n",
      "D_fake_acc: 0.82455\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 5\n",
      "training D Loss: 0.00047029323279857636\n",
      "training G Loss: 0.001478707104921341\n",
      "D_real_acc: 0.785775\n",
      "D_fake_acc: 0.791525\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 6\n",
      "training D Loss: 0.0005068815052509308\n",
      "training G Loss: 0.0013298166632652283\n",
      "D_real_acc: 0.77625\n",
      "D_fake_acc: 0.804325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 7\n",
      "training D Loss: 0.00044065897166728973\n",
      "training G Loss: 0.0015513265907764434\n",
      "D_real_acc: 0.80875\n",
      "D_fake_acc: 0.854725\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 8\n",
      "training D Loss: 0.0005083342164754868\n",
      "training G Loss: 0.0013682247132062913\n",
      "D_real_acc: 0.753975\n",
      "D_fake_acc: 0.791675\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 9\n",
      "training D Loss: 0.0003683216318488121\n",
      "training G Loss: 0.0013452062129974366\n",
      "D_real_acc: 0.82365\n",
      "D_fake_acc: 0.87205\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 10\n",
      "training D Loss: 0.0005576537862420082\n",
      "training G Loss: 0.001430232772231102\n",
      "D_real_acc: 0.76475\n",
      "D_fake_acc: 0.74175\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 11\n",
      "training D Loss: 0.0004958896860480309\n",
      "training G Loss: 0.001359425973892212\n",
      "D_real_acc: 0.72655\n",
      "D_fake_acc: 0.759475\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 12\n",
      "training D Loss: 0.00046896423548460007\n",
      "training G Loss: 0.001395780521631241\n",
      "D_real_acc: 0.760725\n",
      "D_fake_acc: 0.76225\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 13\n",
      "training D Loss: 0.00045631371140480043\n",
      "training G Loss: 0.0016682793766260146\n",
      "D_real_acc: 0.791025\n",
      "D_fake_acc: 0.75805\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 14\n",
      "training D Loss: 0.000444061616063118\n",
      "training G Loss: 0.0016957509785890579\n",
      "D_real_acc: 0.774975\n",
      "D_fake_acc: 0.789025\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 15\n",
      "training D Loss: 0.00044927935153245925\n",
      "training G Loss: 0.001591996294260025\n",
      "D_real_acc: 0.7853\n",
      "D_fake_acc: 0.79065\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 16\n",
      "training D Loss: 0.00043105230703949926\n",
      "training G Loss: 0.0016601433694362641\n",
      "D_real_acc: 0.774275\n",
      "D_fake_acc: 0.805275\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 17\n",
      "training D Loss: 0.00045092975944280625\n",
      "training G Loss: 0.001630097258090973\n",
      "D_real_acc: 0.772025\n",
      "D_fake_acc: 0.7642\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 18\n",
      "training D Loss: 0.0004817849516868591\n",
      "training G Loss: 0.0015620980605483056\n",
      "D_real_acc: 0.7679\n",
      "D_fake_acc: 0.8073\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 19\n",
      "training D Loss: 0.0004301380380988121\n",
      "training G Loss: 0.0015359800636768341\n",
      "D_real_acc: 0.790275\n",
      "D_fake_acc: 0.78925\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 20\n",
      "training D Loss: 0.00048614880964159964\n",
      "training G Loss: 0.0015990529298782349\n",
      "D_real_acc: 0.78415\n",
      "D_fake_acc: 0.8256\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 21\n",
      "training D Loss: 0.00045526845678687096\n",
      "training G Loss: 0.0016451795250177384\n",
      "D_real_acc: 0.775175\n",
      "D_fake_acc: 0.778325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 22\n",
      "training D Loss: 0.0004920297302305699\n",
      "training G Loss: 0.0016438643991947173\n",
      "D_real_acc: 0.778\n",
      "D_fake_acc: 0.784025\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 23\n",
      "training D Loss: 0.00042365210205316545\n",
      "training G Loss: 0.0016256696432828902\n",
      "D_real_acc: 0.791275\n",
      "D_fake_acc: 0.80665\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 24\n",
      "training D Loss: 0.00043116439878940584\n",
      "training G Loss: 0.0015212805777788162\n",
      "D_real_acc: 0.79505\n",
      "D_fake_acc: 0.834025\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 25\n",
      "lr changed\n",
      "training D Loss: 0.0003873657718300819\n",
      "training G Loss: 0.0012002250790596007\n",
      "D_real_acc: 0.8529\n",
      "D_fake_acc: 0.887975\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 26\n",
      "training D Loss: 0.0003464467950165272\n",
      "training G Loss: 0.0013452281713485718\n",
      "D_real_acc: 0.85325\n",
      "D_fake_acc: 0.903825\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 27\n",
      "training D Loss: 0.000352724289894104\n",
      "training G Loss: 0.0013861415892839433\n",
      "D_real_acc: 0.853875\n",
      "D_fake_acc: 0.89525\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 28\n",
      "training D Loss: 0.00031163728386163713\n",
      "training G Loss: 0.0013513061225414276\n",
      "D_real_acc: 0.880325\n",
      "D_fake_acc: 0.941425\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 29\n",
      "training D Loss: 0.0003814686104655266\n",
      "training G Loss: 0.0013929071098566055\n",
      "D_real_acc: 0.816975\n",
      "D_fake_acc: 0.853775\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 30\n",
      "training D Loss: 0.00036187364086508753\n",
      "training G Loss: 0.0013352319478988647\n",
      "D_real_acc: 0.845975\n",
      "D_fake_acc: 0.878825\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 31\n",
      "training D Loss: 0.00037488857805728913\n",
      "training G Loss: 0.0013324536502361298\n",
      "D_real_acc: 0.829575\n",
      "D_fake_acc: 0.862425\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 32\n",
      "training D Loss: 0.0004039020389318466\n",
      "training G Loss: 0.0013926980584859849\n",
      "D_real_acc: 0.817975\n",
      "D_fake_acc: 0.870575\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 33\n",
      "training D Loss: 0.00038370568603277207\n",
      "training G Loss: 0.0012882317259907722\n",
      "D_real_acc: 0.83715\n",
      "D_fake_acc: 0.883625\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 34\n",
      "training D Loss: 0.0003253630846738815\n",
      "training G Loss: 0.0012415219277143478\n",
      "D_real_acc: 0.8795\n",
      "D_fake_acc: 0.924475\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 35\n",
      "training D Loss: 0.0004157764732837677\n",
      "training G Loss: 0.001393686956167221\n",
      "D_real_acc: 0.8073\n",
      "D_fake_acc: 0.8634\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 36\n",
      "training D Loss: 0.00037424275130033493\n",
      "training G Loss: 0.0011877059817314147\n",
      "D_real_acc: 0.842875\n",
      "D_fake_acc: 0.91545\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 37\n",
      "training D Loss: 0.00037535111457109453\n",
      "training G Loss: 0.0012581734150648117\n",
      "D_real_acc: 0.829925\n",
      "D_fake_acc: 0.865325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 38\n",
      "training D Loss: 0.0003410158485174179\n",
      "training G Loss: 0.001190616464614868\n",
      "D_real_acc: 0.85995\n",
      "D_fake_acc: 0.90655\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 39\n",
      "training D Loss: 0.0004173114821314812\n",
      "training G Loss: 0.0013167688176035882\n",
      "D_real_acc: 0.81135\n",
      "D_fake_acc: 0.8325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 40\n",
      "training D Loss: 0.000374508298933506\n",
      "training G Loss: 0.0011746156692504883\n",
      "D_real_acc: 0.851875\n",
      "D_fake_acc: 0.888825\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 41\n",
      "training D Loss: 0.00040405648201704024\n",
      "training G Loss: 0.001340542247891426\n",
      "D_real_acc: 0.8037\n",
      "D_fake_acc: 0.845125\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 42\n",
      "training D Loss: 0.0003523444384336472\n",
      "training G Loss: 0.0012415737360715867\n",
      "D_real_acc: 0.8641\n",
      "D_fake_acc: 0.908525\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 43\n",
      "training D Loss: 0.00033837935030460356\n",
      "training G Loss: 0.0011948282122612\n",
      "D_real_acc: 0.858725\n",
      "D_fake_acc: 0.906325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 44\n",
      "training D Loss: 0.00035313120037317277\n",
      "training G Loss: 0.0011417932167649269\n",
      "D_real_acc: 0.845675\n",
      "D_fake_acc: 0.88875\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 45\n",
      "training D Loss: 0.00040446660965681074\n",
      "training G Loss: 0.0012205687180161476\n",
      "D_real_acc: 0.8032\n",
      "D_fake_acc: 0.81515\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 46\n",
      "training D Loss: 0.000393358439207077\n",
      "training G Loss: 0.0012583391189575194\n",
      "D_real_acc: 0.834475\n",
      "D_fake_acc: 0.87665\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 47\n",
      "training D Loss: 0.0004044439733028412\n",
      "training G Loss: 0.0012765355408191682\n",
      "D_real_acc: 0.839175\n",
      "D_fake_acc: 0.851475\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 48\n",
      "training D Loss: 0.000404675729572773\n",
      "training G Loss: 0.001245260089635849\n",
      "D_real_acc: 0.805125\n",
      "D_fake_acc: 0.847325\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 49\n",
      "training D Loss: 0.0003919424414634705\n",
      "training G Loss: 0.001117071783542633\n",
      "D_real_acc: 0.822975\n",
      "D_fake_acc: 0.871225\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 50\n",
      "lr changed\n",
      "training D Loss: 0.0002953915238380432\n",
      "training G Loss: 0.0009502029299736023\n",
      "D_real_acc: 0.929575\n",
      "D_fake_acc: 0.982\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 51\n",
      "training D Loss: 0.0003072738394141197\n",
      "training G Loss: 0.0009206709146499634\n",
      "D_real_acc: 0.92365\n",
      "D_fake_acc: 0.97925\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 52\n",
      "training D Loss: 0.00030867270678281783\n",
      "training G Loss: 0.0009147160887718201\n",
      "D_real_acc: 0.92325\n",
      "D_fake_acc: 0.977975\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 53\n",
      "training D Loss: 0.0002965538650751114\n",
      "training G Loss: 0.0009283368110656738\n",
      "D_real_acc: 0.9344\n",
      "D_fake_acc: 0.979975\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 54\n",
      "training D Loss: 0.0003021329253911972\n",
      "training G Loss: 0.0009551580846309662\n",
      "D_real_acc: 0.9244\n",
      "D_fake_acc: 0.97055\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 55\n",
      "training D Loss: 0.00033186519891023635\n",
      "training G Loss: 0.000961863449215889\n",
      "D_real_acc: 0.8848\n",
      "D_fake_acc: 0.9348\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 56\n",
      "training D Loss: 0.0003063327506184578\n",
      "training G Loss: 0.0009166054368019104\n",
      "D_real_acc: 0.930625\n",
      "D_fake_acc: 0.98005\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 57\n",
      "training D Loss: 0.000314837583899498\n",
      "training G Loss: 0.0009691695064306259\n",
      "D_real_acc: 0.904475\n",
      "D_fake_acc: 0.942725\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 58\n",
      "training D Loss: 0.0002963586300611496\n",
      "training G Loss: 0.0009437407493591308\n",
      "D_real_acc: 0.9272\n",
      "D_fake_acc: 0.96675\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 59\n",
      "training D Loss: 0.0003264068827033043\n",
      "training G Loss: 0.0009712742686271668\n",
      "D_real_acc: 0.887625\n",
      "D_fake_acc: 0.927175\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 60\n",
      "training D Loss: 0.000324724093079567\n",
      "training G Loss: 0.0009906905323266984\n",
      "D_real_acc: 0.897025\n",
      "D_fake_acc: 0.934525\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 61\n",
      "training D Loss: 0.0003260542422533035\n",
      "training G Loss: 0.0009509403049945831\n",
      "D_real_acc: 0.8864\n",
      "D_fake_acc: 0.93065\n",
      "\n",
      "model saved to p2_latest_G.pth\n",
      "model saved to p2_latest_D.pth\n",
      "Epoch: 62\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# setup optimizer\n",
    "optimizerG = optim.Adam(G.parameters(), lr=0.0004, betas=(0.5, 0.999))\n",
    "optimizerD = optim.Adam(D.parameters(), lr=0.0004, betas=(0.5, 0.999))\n",
    "\n",
    "#th.loadModel('p2_latest_G.pth',G,optimizerG)\n",
    "#th.loadModel('p2_latest_D.pth',D,optimizerD)\n",
    "\n",
    "D_loss_list = np.load(\"hw3_data/p2_plot_npy/D_loss_list.npy\").tolist()\n",
    "G_loss_list = np.load(\"hw3_data/p2_plot_npy/G_loss_list.npy\").tolist()\n",
    "D_fake_acc_list = np.load(\"hw3_data/p2_plot_npy/D_fake_acc_list.npy\").tolist()\n",
    "D_real_acc_list = np.load(\"hw3_data/p2_plot_npy/D_real_acc_list.npy\").tolist()\n",
    "\n",
    "D_loss_list = []\n",
    "G_loss_list = []\n",
    "D_fake_acc_list = []\n",
    "D_real_acc_list = []\n",
    "\n",
    "fixedNoise = Variable(torch.randn(32, 100, 1, 1)).to(device)\n",
    "\n",
    "while len(D_loss_list) < 100:\n",
    "    print(\"Epoch:\", len(D_loss_list))\n",
    "    epoch_D_loss, epoch_G_loss, D_fake_acc, D_real_acc  = 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    if len(D_loss_list) % 25 == 0:\n",
    "        optimizerG.param_groups[0]['lr'] /= 2\n",
    "        optimizerD.param_groups[0]['lr'] /= 2\n",
    "        print(\"lr changed\")\n",
    "        \n",
    "    for batch_idx, data in enumerate(trainset_loader):\n",
    "        D.zero_grad()\n",
    "        \n",
    "        #### train with real image -> ground truth = real label\n",
    "        real_image = Variable(data).to(device)\n",
    "        real_label = Variable(torch.ones(len(data))).to(device)\n",
    "        output = D(real_image)\n",
    "        D_real_loss = criterion(output, real_label)\n",
    "        D_real_acc += np.sum(((output > 0.5).cpu().data.numpy() == real_label.cpu().data.numpy()))\n",
    "        \n",
    "        #### train with fake image -> ground truth = fake label\n",
    "        noise = Variable(torch.randn((len(data),100,1,1))).to(device)\n",
    "        fake_image = G(noise)\n",
    "        fake_label = Variable(torch.zeros(len(data))).to(device)\n",
    "        output = D(fake_image.detach())\n",
    "        D_fake_loss = criterion(output, fake_label)\n",
    "        D_fake_acc += np.sum(((output > 0.5).cpu().data.numpy() == fake_label.cpu().data.numpy()))\n",
    "        \n",
    "        # update D\n",
    "        D_train_loss = D_real_loss + D_fake_loss\n",
    "        epoch_D_loss += float(D_train_loss.data)\n",
    "        D_train_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        #### train Generator\n",
    "        gIte = 1\n",
    "        for i in range(gIte):\n",
    "            G.zero_grad()\n",
    "            # generate fake image\n",
    "            noise = Variable(torch.randn(len(data),100,1,1)).to(device)\n",
    "            fake_image = G(noise)\n",
    "            fake_label_for_G = Variable(torch.ones(len(data))).to(device)\n",
    "            output = D(fake_image)\n",
    "            G_loss = criterion(output, fake_label_for_G)\n",
    "            epoch_G_loss += float(G_loss.data)/gIte\n",
    "            G_loss.backward()\n",
    "            optimizerG.step()\n",
    "    \n",
    "    print(\"training D Loss:\",epoch_D_loss/len(trainset))\n",
    "    print(\"training G Loss:\", epoch_G_loss/len(trainset))\n",
    "    D_loss_list.append(epoch_D_loss/len(trainset))\n",
    "    G_loss_list.append(epoch_G_loss/len(trainset))\n",
    "    \n",
    "    print(\"D_real_acc:\", D_real_acc/len(trainset))\n",
    "    print(\"D_fake_acc:\", D_fake_acc/len(trainset))\n",
    "    print('')\n",
    "    \n",
    "    D_real_acc_list.append(D_real_acc/len(trainset))\n",
    "    D_fake_acc_list.append(D_fake_acc/len(trainset))\n",
    "    \n",
    "    \n",
    "    th.saveModel('p2_latest_G.pth',G,optimizerG)\n",
    "    th.saveModel('p2_latest_D.pth',D,optimizerD)\n",
    "    \n",
    "    G.eval()\n",
    "    generatedImages = G(fixedNoise)\n",
    "    G.train()\n",
    "    \n",
    "    torchvision.utils.save_image(generatedImages.cpu().data, 'hw3_data/p2_generator_images/ep-'+str(len(D_loss_list)-1)+'.jpg', nrow=8)\n",
    "    np.save(\"hw3_data/p2_plot_npy/D_loss_list.npy\", D_loss_list)\n",
    "    np.save(\"hw3_data/p2_plot_npy/G_loss_list.npy\", G_loss_list)\n",
    "    np.save(\"hw3_data/p2_plot_npy/D_real_acc_list.npy\", D_real_acc_list)\n",
    "    np.save(\"hw3_data/p2_plot_npy/D_fake_acc_list.npy\", D_fake_acc_list)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
